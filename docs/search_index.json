[["index.html", "Python Cookbook for the Casual Dabbler Chapter 1 Welcome", " Python Cookbook for the Casual Dabbler Charles Coverdale 2022-04-12 Chapter 1 Welcome G’day! "],["making-beautiful-charts-in-python.html", "Chapter 2 Making beautiful charts in Python 2.1 What’s in a chart? 2.2 Importing python packages 2.3 Importing and cleaning data 2.4 Bar charts 2.5 Stacked bar charts 2.6 Line charts 2.7 Scatter plot 2.8 Histogram 2.9 Multiple charts in single plot 2.10 Annotating charts 2.11 Making maps with python 2.12 Importing python packages 2.13 Making simple maps with geopandas 2.14 Geocoding address data 2.15 Open Street Map", " Chapter 2 Making beautiful charts in Python 2.1 What’s in a chart? XX 2.2 Importing python packages Let’s load in some libraries that we will use again and again when making charts. import matplotlib.pyplot as plt import matplotlib.dates as mdates import pandas as pd import numpy as np import statistics from scipy.stats import norm from matplotlib.ticker import EngFormatter, StrMethodFormatter 2.3 Importing and cleaning data #Note non-ascii character in csv will stuff up the import, so we add this term: encoding=&#39;unicode_escape&#39; # Note: The full file location is this: # /Users/charlescoverdale/Documents/2021/Python_code_projects/learning_journal_v0-1/MEL_weather_2019.csv # Import csv df_weather= pd.read_csv(&quot;MEL_weather_2019.csv&quot;,encoding=&#39;unicode_escape&#39;) # Create a single data column and bind to df df_weather[&#39;Date&#39;] = pd.to_datetime(df_weather[[&#39;Year&#39;, &#39;Month&#39;, &#39;Day&#39;]]) # Drop the original three field date columns df_weather = df_weather.drop(columns=[&#39;Year&#39;, &#39;Month&#39;, &#39;Day&#39;]) # Let&#39;s change the name of the solar exposure column df_weather = df_weather.rename({&#39;Daily global solar exposure (MJ/m*m)&#39;:&#39;Solar_exposure&#39;, &#39;Rainfall amount (millimetres)&#39;:&#39;Rainfall&#39;, &#39;Maximum temperature (°C)&#39;: &#39;Max_temp&#39;}, axis=1) #Add a rolling average df_weather[&#39;Rolling_avg&#39;] = df_weather[&#39;Max_temp&#39;].rolling(window=7).mean() df_weather.head() # Now let&#39;s plot maximum temperature on a line chart plt.plot(df_weather[&#39;Date&#39;], df_weather[&#39;Max_temp&#39;], label=&#39;Maximum temperature&#39;, color=&#39;blue&#39;, alpha=0.2, linewidth=1.0, marker=&#39;&#39;) plt.plot(df_weather[&#39;Date&#39;], df_weather[&#39;Rolling_avg&#39;], label=&#39;7-day moving average&#39;, color=&#39;red&#39;, linewidth=1.0, marker=&#39;&#39;) plt.title(&#39;Maximum temperature in Melbourne (2019)&#39;, fontsize=12) plt.xlabel(&#39;&#39;, fontsize=10) plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b&#39;)) plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1)) #plt.margins(x=0) plt.ylabel(&#39;&#39;, fontsize=10) plt.gca().yaxis.set_major_formatter(StrMethodFormatter(u&quot;{x:.0f}°C&quot;)) plt.gca().spines[&#39;top&#39;].set_visible(False) plt.gca().spines[&#39;bottom&#39;].set_visible(True) plt.gca().spines[&#39;right&#39;].set_visible(False) plt.gca().spines[&#39;left&#39;].set_visible(False) plt.tick_params( axis=&#39;x&#39;, # changes apply to the x-axis which=&#39;both&#39;, # both major and minor ticks are affected bottom=False, # ticks along the bottom edge are off top=False, # ticks along the top edge are off labelbottom=True) # labels along the bottom edge are off plt.tick_params( axis=&#39;y&#39;, # changes apply to the y-axis which=&#39;both&#39;, # both major and minor ticks are affected left=False, # ticks along the bottom edge are off right=False, # ticks along the top edge are off labelleft=True) # labels along the bottom edge are off plt.grid(False) plt.gca().yaxis.grid(True) plt.legend(fancybox=False, framealpha=1, shadow=False, borderpad=1) plt.savefig(&#39;weather_chart_save.png&#39;,dpi=300,bbox_inches=&#39;tight&#39;) plt.show() 2.4 Bar charts # Chart 1: Bar plot # Get data country = [&#39;USA&#39;, &#39;Canada&#39;, &#39;Germany&#39;, &#39;UK&#39;, &#39;France&#39;] GDP_per_capita = [45,40,38,16,10] # Create plot plt.bar(country, GDP_per_capita, width=0.8, align=&#39;center&#39;,color=&#39;blue&#39;, edgecolor = &#39;black&#39;) # Labels and titles plt.title(&#39;GDP per capita of select OECD countries&#39;) plt.xlabel(&#39;Test x label&#39;) plt.ylabel(&#39;&#39;) #A dd bar annotations to barchart # Location for the annotated text i = 1.0 j = 1.0 # Annotating the bar plot with the values (total death count) for i in range(len(country)): plt.annotate(GDP_per_capita[i], (-0.1 + i, GDP_per_capita[i] + j)) # Creating the legend of the bars in the plot plt.legend(labels = [&#39;GDP_per_capita&#39;]) # Remove y the axis plt.yticks([]) # plt.savefig(&#39;test_bar_plot.png&#39;,dpi=300,bbox_inches=&#39;tight&#39;) # Show plot plt.show() # Saving the plot as a &#39;png&#39; #plt.savefig(&#39;testbarplot.png&#39;) 2.5 Stacked bar charts labels = [&#39;Group 1&#39;, &#39;Group 2&#39;, &#39;Group 3&#39;, &#39;Group 4&#39;, &#39;Group 5&#39;] men_means = [20, 35, 30, 35, 27] women_means = [25, 32, 34, 20, 25] men_std = [2, 3, 4, 1, 2] women_std = [3, 5, 2, 3, 3] width = 0.7 # the width of the bars: can also be len(x) sequence fig, ax = plt.subplots() ax.bar(labels, men_means, width, yerr=men_std, label=&#39;Men&#39;) ax.bar(labels, women_means, width, yerr=women_std, bottom=men_means, label=&#39;Women&#39;) ax.set_ylabel(&#39;Scores&#39;) ax.set_title(&#39;Scores by group and gender&#39;) ax.legend() plt.show() 2.6 Line charts import matplotlib.ticker as mtick # Note: you can also get the same result without using a pandas dataframe #Year = [1920,1930,1940,1950,1960,1970,1980,1990,2000,2010] #Unemployment_Rate = [9.8,12,8,7.2,6.9,7,6.5,6.2,5.5,6.3] #Using a pandas dataframe Data = {&#39;Year&#39;: [1920,1930,1940,1950,1960,1970,1980,1990,2000,2010], &#39;Unemployment_Rate&#39;: [9.8,12,8,7.2,6.9,7,6.5,6.2,5.5,6.3] } df = pd.DataFrame(Data,columns=[&#39;Year&#39;,&#39;Unemployment_Rate&#39;]) #Add in a % sign to a new variable #df[&#39;Unemployment_Rate_Percent&#39;] = df[&#39;Unemployment_Rate&#39;].astype(str) + &#39;%&#39; plt.plot(df[&#39;Year&#39;], df[&#39;Unemployment_Rate&#39;], color=&#39;blue&#39;, marker=&#39;o&#39;) plt.title(&#39;Unemployment rate (1920-2010)&#39;, fontsize=12) plt.xlabel(&#39;Year&#39;, fontsize=12) plt.ylabel(&#39;&#39;, fontsize=12) #plt.grid(False) plt.gca().yaxis.grid(True) plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter()) plt.show() 2.7 Scatter plot x =[5, 7, 8, 7, 2, 17, 2, 9, 4, 11, 12, 9, 6] y =[99, 86, 87, 88, 100, 86, 103, 87, 94, 78, 77, 85, 86] plt.scatter(x, y, c =&quot;blue&quot;) plt.title(&#39;Scatterplot title&#39;, fontsize=12) plt.xlabel(&#39;x label&#39;, fontsize=12) plt.ylabel(&#39;y label&#39;, fontsize=12) plt.show() 2.8 Histogram np.random.seed(99) # Using the format np.random.normal(mu, sigma, 1000) x = np.random.normal(0,1,size=1000) # Use density=False for counts, and density=True for probability plt.hist(x, density=False, bins=100) # Plot mean line plt.axvline(x.mean(), color=&#39;k&#39;, linestyle=&#39;dashed&#39;, linewidth=1) plt.ylabel(&#39;Probability&#39;) plt.xlabel(&#39;Mean&#39;); plt.show() 2.9 Multiple charts in single plot fig, (ax,ax2) = plt.subplots(ncols=2) ax.plot([0,1],[-35,30]) ax.yaxis.set_major_formatter(EngFormatter(unit=u&quot;°C&quot;)) ax2.plot([0,1],[-35,30]) ax2.yaxis.set_major_formatter(StrMethodFormatter(u&quot;{x:.0f} °C&quot;)) plt.tight_layout() plt.show() 2.10 Annotating charts Example taken from the wonderful blog at Practical Economics. plt.title(&#39;Employment Impact of a Minimum Wage&#39;) # Set limits of chart plt.xlim(10,70) plt.ylim(130,200) # Wage supply floor plt.plot([10,30],[150,150],color=&#39;orange&#39;) plt.text(10.5,140.0,&quot;Marginal\\nDisutility\\nof Labour&quot;,size=8,color=&#39;black&#39;) plt.plot([10,40],[160,160],color=&#39;lightgrey&#39;,linestyle=&#39;--&#39;) plt.plot([40,40],[130,160],color=&#39;lightgrey&#39;,linestyle=&#39;--&#39;) plt.annotate(&#39;&#39;, xy=(30,138),xytext=(40,138),arrowprops = dict(arrowstyle=&#39;&lt;-&gt;&#39;)) plt.text(31,140,&quot;Employment\\nLoss&quot;,size=8, color=&#39;k&#39;) plt.axhspan(170,150,xmin=0.0,xmax=20/60,alpha=0.9,color=&#39;dodgerblue&#39;) plt.annotate(&#39;Additional Surplus to\\nEmployed&#39;, xy=(20,162),xytext=(30,185),arrowprops = dict(arrowstyle=&#39;-&gt;&#39;)) # Deadweight loss triangles trianglex=[30,30,40,30] triangley=[150,170,160,150] plt.plot(trianglex,triangley, color=&#39;grey&#39;) plt.fill(trianglex,triangley,color=&#39;grey&#39;) # Main box plt.plot([10,30],[170,170],&#39;tab:orange&#39;) plt.plot([30,30],[130,170],&#39;tab:green&#39;) #plt.plot([50,50],[130,170],&#39;tab:red&#39;) plt.text(11,171,&quot;Wage Rate&quot;,size=8,color=&#39;black&#39;) plt.annotate(&#39;Deadweight\\nLoss&#39;, xy=(32,162),xytext=(38,175),arrowprops = dict(arrowstyle=&#39;-&gt;&#39;)) #Labour Demand Curve plt.plot([20,60],[180,140],color=&#39;tab:grey&#39;) plt.text(61,135,&quot;Marginal\\nProduct\\nof Labour\\nDemand&quot;,size=8,color=&#39;black&#39;) #Labour Supply Curve plt.plot([20,60],[140,180],color=&#39;tab:grey&#39;) plt.text(61,180,&quot;Labour\\nSupply&quot;,size=8,color=&#39;k&#39;) plt.show() 2.11 Making maps with python 2.12 Importing python packages Let’s load in some libraries that we will use again and again when making charts. import matplotlib.pyplot as plt import matplotlib.dates as mdates import pandas as pd import geopandas as gpd import numpy as np import statistics from scipy.stats import norm from matplotlib.ticker import EngFormatter, StrMethodFormatter 2.13 Making simple maps with geopandas Just like a pandas dataframe, the geopandas package allows us to us shapefiles. We’ll go ahead and download some shapefiles from the ABS. # Read the SHP file SA4_shp = gpd.read_file(&#39;ASGS/SA4_2021_AUST_SHP_GDA2020/SA4_2021_AUST_GDA2020.shp&#39;) # Load the data using Geopandas SA4_shp.head() # Check the coordinate reference system attached to the shapefile ## SA4_CODE21 ... geometry ## 0 101 ... MULTIPOLYGON (((150.05261 -37.26253, 150.05251... ## 1 102 ... MULTIPOLYGON (((151.31497 -33.55578, 151.31496... ## 2 103 ... POLYGON ((150.14236 -32.34153, 150.14255 -32.3... ## 3 104 ... MULTIPOLYGON (((153.07639 -30.42982, 153.07645... ## 4 105 ... POLYGON ((148.67619 -29.50976, 148.67662 -29.5... ## ## [5 rows x 13 columns] SA4_shp.crs # Filter the data for only Greater Melbourne ## &lt;Geographic 2D CRS: EPSG:7844&gt; ## Name: GDA2020 ## Axis Info [ellipsoidal]: ## - Lat[north]: Geodetic latitude (degree) ## - Lon[east]: Geodetic longitude (degree) ## Area of Use: ## - name: Australia including Lord Howe Island, Macquarie Island, Ashmore and Cartier Islands, Christmas Island, Cocos (Keeling) Islands, Norfolk Island. All onshore and offshore. ## - bounds: (93.41, -60.55, 173.34, -8.47) ## Datum: Geocentric Datum of Australia 2020 ## - Ellipsoid: GRS 1980 ## - Prime Meridian: Greenwich SA4_shp_MEL = SA4_shp[SA4_shp[&#39;GCC_NAME21&#39;]==&#39;Greater Melbourne&#39;] SA4_shp_MEL.head() # Quick plot of the shapefile ## SA4_CODE21 ... geometry ## 35 206 ... POLYGON ((145.02062 -37.75442, 145.02307 -37.7... ## 36 207 ... POLYGON ((145.16229 -37.73770, 145.16243 -37.7... ## 37 208 ... POLYGON ((145.07352 -37.99858, 145.07339 -37.9... ## 38 209 ... POLYGON ((145.05522 -37.28651, 145.05547 -37.2... ## 39 210 ... POLYGON ((144.95001 -37.51126, 144.95029 -37.5... ## ## [5 rows x 13 columns] SA4_shp_MEL.plot(figsize=(20, 20), linewidth=0.1, edgecolor=&#39;0.9&#39;, legend = True) plt.annotate(&#39;Melbourne\\nCBD&#39;, xy=(144.96246,-37.81214), xytext=(144.46246,-38.21), arrowprops = dict(arrowstyle=&#39;-&#39;)) plt.title(&quot;SA2&#39;s of Greater Melbourne&quot;, fontsize=12) plt.gca().axis(&#39;off&#39;) ## (144.25640123076812, 145.95565667355476, -38.56936930909917, -37.10869135259332) plt.show() Here’s another example using a shapefile for WA # Load Geometry File WA_shp = gpd.read_file(&#39;data/NOV21_WA_LOC_POLYGON_shp_GDA2020/wa_localities.shp&#39;) WA_shp.plot(figsize=(20, 20), linewidth=0.1, color=&#39;green&#39;, edgecolor=&#39;0.9&#39;, legend = True) plt.title(&quot;Western Australia&quot;, fontsize=12) plt.gca().axis(&#39;off&#39;) ## (112.11683913762016, 129.80597943076583, -36.204830200778254, -12.669598716628517) plt.show() 2.14 Geocoding address data Using Nominatim to find the coordinates of a street address from geopy.geocoders import Nominatim geolocator = Nominatim(user_agent=&quot;coverdale&quot;) test_location = geolocator.geocode(&quot;150 Collins Street, Melbourne Australia&quot;) print(test_location.address) ## 150, Collins Street, Melbourne, City of Melbourne, Victoria, 3000, Australia print(test_location.latitude, test_location.longitude) ## -37.81457022418258 144.96896311671355 print(test_location.raw) ## {&#39;place_id&#39;: 19898577, &#39;licence&#39;: &#39;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright&#39;, &#39;osm_type&#39;: &#39;way&#39;, &#39;osm_id&#39;: 87337974, &#39;boundingbox&#39;: [&#39;-37.814620224183&#39;, &#39;-37.814520224183&#39;, &#39;144.96891311671&#39;, &#39;144.96901311671&#39;], &#39;lat&#39;: &#39;-37.81457022418258&#39;, &#39;lon&#39;: &#39;144.96896311671355&#39;, &#39;display_name&#39;: &#39;150, Collins Street, Melbourne, City of Melbourne, Victoria, 3000, Australia&#39;, &#39;class&#39;: &#39;place&#39;, &#39;type&#39;: &#39;house&#39;, &#39;importance&#39;: 0.5309999999999999} Using Nominatim to find the street address from a set of coordinates from geopy.geocoders import Nominatim geolocator = Nominatim(user_agent=&quot;coverdale&quot;) test_location = geolocator.reverse(&quot;-37.81214, 144.96246&quot;) print(test_location.address) ## 280, Elizabeth Street, Melbourne Innovation District, Melbourne, City of Melbourne, Victoria, 3000, Australia print(test_location.latitude, test_location.longitude) ## -37.8121701209085 144.9623730375179 print(test_location.raw) ## {&#39;place_id&#39;: 20040922, &#39;licence&#39;: &#39;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright&#39;, &#39;osm_type&#39;: &#39;way&#39;, &#39;osm_id&#39;: 88318376, &#39;lat&#39;: &#39;-37.8121701209085&#39;, &#39;lon&#39;: &#39;144.9623730375179&#39;, &#39;display_name&#39;: &#39;280, Elizabeth Street, Melbourne Innovation District, Melbourne, City of Melbourne, Victoria, 3000, Australia&#39;, &#39;address&#39;: {&#39;house_number&#39;: &#39;280&#39;, &#39;road&#39;: &#39;Elizabeth Street&#39;, &#39;commercial&#39;: &#39;Melbourne Innovation District&#39;, &#39;suburb&#39;: &#39;Melbourne&#39;, &#39;city&#39;: &#39;Melbourne&#39;, &#39;municipality&#39;: &#39;City of Melbourne&#39;, &#39;state&#39;: &#39;Victoria&#39;, &#39;postcode&#39;: &#39;3000&#39;, &#39;country&#39;: &#39;Australia&#39;, &#39;country_code&#39;: &#39;au&#39;}, &#39;boundingbox&#39;: [&#39;-37.812220120908&#39;, &#39;-37.812120120908&#39;, &#39;144.96232303752&#39;, &#39;144.96242303752&#39;]} We can also use geopy to find the distance between two points Geopy can calculate geodesic distance between two points using the geodesic distance or the great-circle distance, with a default of the geodesic distance available as the function geopy.distance.distance. #Here&#39;s an example usage of the geodesic distance: from geopy.distance import geodesic sydney = (-37.81214, 144.96246) melbourne = (-33.8688, 151.2093) print(geodesic(sydney, melbourne).kilometers) # Using great-circle distance: ## 713.8082136217063 from geopy.distance import great_circle sydney = (-37.81214, 144.96246) melbourne = (-33.8688, 151.2093) print(great_circle(sydney, melbourne).kilometers) ## 713.3784038434918 Note we see a slight difference in the km measurement (around 500m) - this is due to the earth not being exactly spherical. Geocoding a list of addresses hospital_data_clean = hospital_data.dropna() # Split out the points into latitude and longitude hospital_data_clean[[‘lat,’ ‘lon,’ ‘altitude’]] = pd.DataFrame(hospital_data[‘point’].to_list(), index=hospital_data.index) # View dataframe hospital_data_clean.head(5) # Import necessary modules import geopy import geocoder import geopandas as gpd from shapely.geometry import Point from geopandas.tools import geocode from geopy.geocoders import Nominatim geolocator = Nominatim(user_agent=&quot;coverdale&quot;) from geopy.extra.rate_limiter import RateLimiter geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1) # Read the data hospital_data = pd.read_csv(&quot;data/QLD_public_hospitals.csv&quot;, on_bad_lines=&#39;skip&#39;, encoding=&#39;unicode_escape&#39;) hospital_data.head(5) # Add the state and country to the data ## Hospital and Health Service ... Fax Number ## 0 Cairns and Hinterland ... (07) 4091 0401 ## 1 Cairns and Hinterland ... (07) 4067 1641 ## 2 Cairns and Hinterland ... (07) 4031 1168 ## 3 Cairns and Hinterland ... (07) 4043 3199 ## 4 Cairns and Hinterland ... (07) 4096 2451 ## ## [5 rows x 6 columns] hospital_data[&#39;Address&#39;] = hospital_data[&#39;Address&#39;].astype(str) + &quot;, Queensland, Australia&quot; # Find the location hospital_data[&#39;location&#39;] = hospital_data[&#39;Address&#39;].apply(geocode) # Turn the location into a point ## RateLimiter caught an error, retrying (0/2 tries). Called with (*(&#39;1 Victoria Street, St George, 4487, Queensland, Australia&#39;,), **{}). ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 445, in _make_request ## six.raise_from(e, None) ## File &quot;&lt;string&gt;&quot;, line 3, in raise_from ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 440, in _make_request ## httplib_response = conn.getresponse() ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/http/client.py&quot;, line 1374, in getresponse ## response.begin() ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/http/client.py&quot;, line 318, in begin ## version, status, reason = self._read_status() ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/http/client.py&quot;, line 279, in _read_status ## line = str(self.fp.readline(_MAXLINE + 1), &quot;iso-8859-1&quot;) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/socket.py&quot;, line 705, in readinto ## return self._sock.recv_into(b) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/ssl.py&quot;, line 1273, in recv_into ## return self.read(nbytes, buffer) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/ssl.py&quot;, line 1129, in read ## return self._sslobj.read(len, buffer) ## TimeoutError: The read operation timed out ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 699, in urlopen ## httplib_response = self._make_request( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 447, in _make_request ## self._raise_timeout(err=e, url=url, timeout_value=read_timeout) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 336, in _raise_timeout ## raise ReadTimeoutError( ## urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1) ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/adapters.py&quot;, line 439, in send ## resp = conn.urlopen( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 783, in urlopen ## return self.urlopen( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 783, in urlopen ## return self.urlopen( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 755, in urlopen ## retries = retries.increment( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/util/retry.py&quot;, line 574, in increment ## raise MaxRetryError(_pool, url, error or ResponseError(cause)) ## urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Max retries exceeded with url: /search?q=1+Victoria+Street%2C+St+George%2C+4487%2C+Queensland%2C+Australia&amp;format=json&amp;limit=1 (Caused by ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1)&quot;)) ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/adapters.py&quot;, line 448, in _request ## resp = self.session.get(url, timeout=timeout, headers=headers) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/sessions.py&quot;, line 555, in get ## return self.request(&#39;GET&#39;, url, **kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/sessions.py&quot;, line 542, in request ## resp = self.send(prep, **send_kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/sessions.py&quot;, line 655, in send ## r = adapter.send(request, **kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/adapters.py&quot;, line 516, in send ## raise ConnectionError(e, request=request) ## requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Max retries exceeded with url: /search?q=1+Victoria+Street%2C+St+George%2C+4487%2C+Queensland%2C+Australia&amp;format=json&amp;limit=1 (Caused by ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1)&quot;)) ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/extra/rate_limiter.py&quot;, line 136, in _retries_gen ## yield i # Run the function. ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/extra/rate_limiter.py&quot;, line 274, in __call__ ## res = self.func(*args, **kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/geocoders/nominatim.py&quot;, line 297, in geocode ## return self._call_geocoder(url, callback, timeout=timeout) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/geocoders/base.py&quot;, line 368, in _call_geocoder ## result = self.adapter.get_json(url, timeout=timeout, headers=req_headers) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/adapters.py&quot;, line 438, in get_json ## resp = self._request(url, timeout=timeout, headers=headers) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/adapters.py&quot;, line 460, in _request ## raise GeocoderUnavailable(message) ## geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Max retries exceeded with url: /search?q=1+Victoria+Street%2C+St+George%2C+4487%2C+Queensland%2C+Australia&amp;format=json&amp;limit=1 (Caused by ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1)&quot;)) ## RateLimiter caught an error, retrying (1/2 tries). Called with (*(&#39;1 Victoria Street, St George, 4487, Queensland, Australia&#39;,), **{}). ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 445, in _make_request ## six.raise_from(e, None) ## File &quot;&lt;string&gt;&quot;, line 3, in raise_from ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 440, in _make_request ## httplib_response = conn.getresponse() ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/http/client.py&quot;, line 1374, in getresponse ## response.begin() ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/http/client.py&quot;, line 318, in begin ## version, status, reason = self._read_status() ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/http/client.py&quot;, line 279, in _read_status ## line = str(self.fp.readline(_MAXLINE + 1), &quot;iso-8859-1&quot;) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/socket.py&quot;, line 705, in readinto ## return self._sock.recv_into(b) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/ssl.py&quot;, line 1273, in recv_into ## return self.read(nbytes, buffer) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/ssl.py&quot;, line 1129, in read ## return self._sslobj.read(len, buffer) ## TimeoutError: The read operation timed out ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 699, in urlopen ## httplib_response = self._make_request( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 447, in _make_request ## self._raise_timeout(err=e, url=url, timeout_value=read_timeout) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 336, in _raise_timeout ## raise ReadTimeoutError( ## urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1) ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/adapters.py&quot;, line 439, in send ## resp = conn.urlopen( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 783, in urlopen ## return self.urlopen( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 783, in urlopen ## return self.urlopen( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 755, in urlopen ## retries = retries.increment( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/util/retry.py&quot;, line 574, in increment ## raise MaxRetryError(_pool, url, error or ResponseError(cause)) ## urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Max retries exceeded with url: /search?q=1+Victoria+Street%2C+St+George%2C+4487%2C+Queensland%2C+Australia&amp;format=json&amp;limit=1 (Caused by ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1)&quot;)) ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/adapters.py&quot;, line 448, in _request ## resp = self.session.get(url, timeout=timeout, headers=headers) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/sessions.py&quot;, line 555, in get ## return self.request(&#39;GET&#39;, url, **kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/sessions.py&quot;, line 542, in request ## resp = self.send(prep, **send_kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/sessions.py&quot;, line 655, in send ## r = adapter.send(request, **kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/adapters.py&quot;, line 516, in send ## raise ConnectionError(e, request=request) ## requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Max retries exceeded with url: /search?q=1+Victoria+Street%2C+St+George%2C+4487%2C+Queensland%2C+Australia&amp;format=json&amp;limit=1 (Caused by ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1)&quot;)) ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/extra/rate_limiter.py&quot;, line 136, in _retries_gen ## yield i # Run the function. ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/extra/rate_limiter.py&quot;, line 274, in __call__ ## res = self.func(*args, **kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/geocoders/nominatim.py&quot;, line 297, in geocode ## return self._call_geocoder(url, callback, timeout=timeout) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/geocoders/base.py&quot;, line 368, in _call_geocoder ## result = self.adapter.get_json(url, timeout=timeout, headers=req_headers) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/adapters.py&quot;, line 438, in get_json ## resp = self._request(url, timeout=timeout, headers=headers) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/adapters.py&quot;, line 460, in _request ## raise GeocoderUnavailable(message) ## geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Max retries exceeded with url: /search?q=1+Victoria+Street%2C+St+George%2C+4487%2C+Queensland%2C+Australia&amp;format=json&amp;limit=1 (Caused by ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1)&quot;)) ## RateLimiter swallowed an error after 2 retries. Called with (*(&#39;1 Victoria Street, St George, 4487, Queensland, Australia&#39;,), **{}). ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 445, in _make_request ## six.raise_from(e, None) ## File &quot;&lt;string&gt;&quot;, line 3, in raise_from ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 440, in _make_request ## httplib_response = conn.getresponse() ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/http/client.py&quot;, line 1374, in getresponse ## response.begin() ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/http/client.py&quot;, line 318, in begin ## version, status, reason = self._read_status() ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/http/client.py&quot;, line 279, in _read_status ## line = str(self.fp.readline(_MAXLINE + 1), &quot;iso-8859-1&quot;) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/socket.py&quot;, line 705, in readinto ## return self._sock.recv_into(b) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/ssl.py&quot;, line 1273, in recv_into ## return self.read(nbytes, buffer) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/ssl.py&quot;, line 1129, in read ## return self._sslobj.read(len, buffer) ## TimeoutError: The read operation timed out ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 699, in urlopen ## httplib_response = self._make_request( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 447, in _make_request ## self._raise_timeout(err=e, url=url, timeout_value=read_timeout) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 336, in _raise_timeout ## raise ReadTimeoutError( ## urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1) ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/adapters.py&quot;, line 439, in send ## resp = conn.urlopen( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 783, in urlopen ## return self.urlopen( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 783, in urlopen ## return self.urlopen( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 755, in urlopen ## retries = retries.increment( ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/urllib3/util/retry.py&quot;, line 574, in increment ## raise MaxRetryError(_pool, url, error or ResponseError(cause)) ## urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Max retries exceeded with url: /search?q=1+Victoria+Street%2C+St+George%2C+4487%2C+Queensland%2C+Australia&amp;format=json&amp;limit=1 (Caused by ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1)&quot;)) ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/adapters.py&quot;, line 448, in _request ## resp = self.session.get(url, timeout=timeout, headers=headers) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/sessions.py&quot;, line 555, in get ## return self.request(&#39;GET&#39;, url, **kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/sessions.py&quot;, line 542, in request ## resp = self.send(prep, **send_kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/sessions.py&quot;, line 655, in send ## r = adapter.send(request, **kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/requests/adapters.py&quot;, line 516, in send ## raise ConnectionError(e, request=request) ## requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Max retries exceeded with url: /search?q=1+Victoria+Street%2C+St+George%2C+4487%2C+Queensland%2C+Australia&amp;format=json&amp;limit=1 (Caused by ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1)&quot;)) ## ## During handling of the above exception, another exception occurred: ## ## Traceback (most recent call last): ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/extra/rate_limiter.py&quot;, line 274, in __call__ ## res = self.func(*args, **kwargs) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/geocoders/nominatim.py&quot;, line 297, in geocode ## return self._call_geocoder(url, callback, timeout=timeout) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/geocoders/base.py&quot;, line 368, in _call_geocoder ## result = self.adapter.get_json(url, timeout=timeout, headers=req_headers) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/adapters.py&quot;, line 438, in get_json ## resp = self._request(url, timeout=timeout, headers=headers) ## File &quot;/Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/geopy/adapters.py&quot;, line 460, in _request ## raise GeocoderUnavailable(message) ## geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Max retries exceeded with url: /search?q=1+Victoria+Street%2C+St+George%2C+4487%2C+Queensland%2C+Australia&amp;format=json&amp;limit=1 (Caused by ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#39;nominatim.openstreetmap.org&#39;, port=443): Read timed out. (read timeout=1)&quot;)) hospital_data[&#39;point&#39;] = hospital_data[&#39;location&#39;].apply(lambda loc: tuple(loc.point) if loc else None) hospital_data_clean = hospital_data.dropna() # Split out the points into latitude and longitude hospital_data_clean[[&#39;lat&#39;, &#39;lon&#39;, &#39;altitude&#39;]] = pd.DataFrame(hospital_data_clean[&#39;point&#39;].to_list(), index=hospital_data_clean.index) ## /Users/charlescoverdale/Library/r-miniconda/envs/r-reticulate/lib/python3.10/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: ## A value is trying to be set on a copy of a slice from a DataFrame. ## Try using .loc[row_indexer,col_indexer] = value instead ## ## See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy ## self[k1] = value[k2] geometry = [Point(xy) for xy in zip (hospital_data_clean[&#39;lon&#39;], hospital_data_clean[&#39;lat&#39;])] hospital_geodataframe = gpd.GeoDataFrame(hospital_data_clean, crs=&quot;EPSG:4326&quot;, geometry=geometry) #hospital_geodataframe.set_crs(epsg=4326, inplace=True) # View dataframe hospital_geodataframe.head(5) ## Hospital and Health Service ... geometry ## 1 Cairns and Hinterland ... POINT (145.92344 -17.34426) ## 3 Cairns and Hinterland ... POINT (145.79955 -17.08100) ## 4 Cairns and Hinterland ... POINT (145.38302 -17.38077) ## 5 Cairns and Hinterland ... POINT (146.03103 -17.52402) ## 6 Cairns and Hinterland ... POINT (145.42182 -16.98907) ## ## [5 rows x 12 columns] Let’s now plot these points on a map of Queensland. We’ll also need to load in the shape of Queensland as the ‘base map.’ # Read the SHP file STE_shp = gpd.read_file(&#39;ASGS/STE_2021_AUST_SHP_GDA2020/STE_2021_AUST_GDA2020.shp&#39;) # Load the data using Geopandas STE_shp.head() # Check the coordinate reference system attached to the shapefile ## STE_CODE21 ... geometry ## 0 1 ... MULTIPOLYGON (((159.06230 -31.50886, 159.06218... ## 1 2 ... MULTIPOLYGON (((146.29286 -39.15778, 146.29341... ## 2 3 ... MULTIPOLYGON (((142.53140 -10.68301, 142.53072... ## 3 4 ... MULTIPOLYGON (((140.66025 -38.06256, 140.66006... ## 4 5 ... MULTIPOLYGON (((117.86953 -35.19108, 117.86961... ## ## [5 rows x 9 columns] STE_shp.crs # Filter the data for only Greater Melbourne ## &lt;Geographic 2D CRS: EPSG:7844&gt; ## Name: GDA2020 ## Axis Info [ellipsoidal]: ## - Lat[north]: Geodetic latitude (degree) ## - Lon[east]: Geodetic longitude (degree) ## Area of Use: ## - name: Australia including Lord Howe Island, Macquarie Island, Ashmore and Cartier Islands, Christmas Island, Cocos (Keeling) Islands, Norfolk Island. All onshore and offshore. ## - bounds: (93.41, -60.55, 173.34, -8.47) ## Datum: Geocentric Datum of Australia 2020 ## - Ellipsoid: GRS 1980 ## - Prime Meridian: Greenwich STE_shp_QLD = STE_shp[STE_shp[&#39;STE_NAME21&#39;]==&#39;Queensland&#39;] STE_shp_QLD.head() ## STE_CODE21 ... geometry ## 2 3 ... MULTIPOLYGON (((142.53140 -10.68301, 142.53072... ## ## [1 rows x 9 columns] Now we plot the two layers together fig, ax = plt.subplots(1, 1, figsize=(12, 12)) # Base layer with all the areas for the background STE_shp_QLD.plot(ax=ax, linewidth=0.1, color=&#39;lightgrey&#39;, edgecolor=&#39;0.9&#39;) # Hospital points hospital_geodataframe.plot(ax=ax, alpha=1, facecolor=&#39;blue&#39;, markersize=5) plt.title(&quot;Hospitals in Queensland&quot;, fontsize=12) ax.set_axis_off() plt.show() 2.15 Open Street Map This exercise loosely follows the wonderful tutorial created by Carlos Cilleruelo. It builds off the OSMnx package that allows us to download spatial data from OpenStreetMap. import osmnx as ox center_point = (-37.81214, 144.96246) G = ox.graph_from_point(center_point, dist=15000, retain_all=True, simplify = True, network_type=&#39;all&#39;) #place = [&quot;Melbourne, Australia&quot;] #G = ox.graph_from_place(place, retain_all=True, simplify = True, network_type=&#39;all&#39;) # Unpack the data u = [] v = [] key = [] data = [] for uu, vv, kkey, ddata in G.edges(keys=True, data=True): u.append(uu) v.append(vv) key.append(kkey) data.append(ddata) # Lists to store colors and widths roadColors = [] roadWidths = [] for item in data: if &quot;length&quot; in item.keys(): if item[&quot;length&quot;] &lt;= 100: linewidth = 0.10 color = &quot;#a6a6a6&quot; elif item[&quot;length&quot;] &gt; 100 and item[&quot;length&quot;] &lt;= 200: linewidth = 0.15 color = &quot;#676767&quot; elif item[&quot;length&quot;] &gt; 200 and item[&quot;length&quot;] &lt;= 400: linewidth = 0.25 color = &quot;#454545&quot; elif item[&quot;length&quot;] &gt; 400 and item[&quot;length&quot;] &lt;= 800: color = &quot;#bdbdbd&quot; linewidth = 0.35 else: color = &quot;#d5d5d5&quot; linewidth = 0.45 if &quot;primary&quot; in item[&quot;highway&quot;]: linewidth = 0.5 color = &quot;#ffff&quot; else: color = &quot;#a6a6a6&quot; linewidth = 0.10 roadColors.append(color) roadWidths.append(linewidth) for item in data: if &quot;footway&quot; in item[&quot;highway&quot;]: color = &quot;#ededed&quot; linewidth = 0.25 else: color = &quot;#a6a6a6&quot; linewidth = 0.5 roadWidths.append(linewidth) #Center of the map latitude = -37.81214 longitude = 144.96246 #Limit borders north = latitude + 0.15 south = latitude - 0.15 east = longitude + 0.15 west = longitude - 0.15 bgcolor = &quot;#061529&quot; fig, ax = ox.plot_graph(G, node_size=0, bbox = (north, south, east, west), dpi = 300,bgcolor = bgcolor, save = False, edge_color=roadColors, edge_linewidth=roadWidths, edge_alpha=1) fig.tight_layout(pad=0) fig.savefig(&quot;madrid.png&quot;, dpi=300, bbox_inches=&#39;tight&#39;, format=&quot;png&quot;, facecolor=fig.get_facecolor(), transparent=False) fig, ax = ox.plot_graph(G, node_size=0,figsize=(27, 40), dpi = 300,bgcolor = bgcolor, save = False, edge_color=roadColors, edge_linewidth=roadWidths, edge_alpha=1) fig.tight_layout(pad=0) fig.savefig(&quot;madridPoster.png&quot;, dpi=300, format=&quot;png&quot;, bbox_inches=&#39;tight&#39;, facecolor=fig.get_facecolor(), transparent=False) We can also add a water layer for the map above (and combine them in photoshop or similiar) import networkx as nx import osmnx as ox center_point = (-37.81214, 144.96246) G1 = ox.graph_from_point(center_point, dist=15000, dist_type=&#39;bbox&#39;, network_type=&#39;all&#39;, simplify=True, retain_all=True, truncate_by_edge=False, clean_periphery=False, custom_filter=&#39;[&quot;natural&quot;~&quot;water&quot;]&#39;) G2 = ox.graph_from_point(center_point, dist=15000, dist_type=&#39;bbox&#39;, network_type=&#39;all&#39;, simplify=True, retain_all=True, truncate_by_edge=False, clean_periphery=False, custom_filter=&#39;[&quot;waterway&quot;~&quot;river&quot;]&#39;) Gwater = nx.compose(G1, G2) u = [] v = [] key = [] data = [] for uu, vv, kkey, ddata in Gwater.edges(keys=True, data=True): u.append(uu) v.append(vv) key.append(kkey) data.append(ddata) # List to store colors roadColors = [] roadWidths = [] # #72b1b1 # #5dc1b9 for item in data: if &quot;name&quot; in item.keys(): if item[&quot;length&quot;] &gt; 400: color = &quot;#72b1b1&quot; linewidth = 2 else: color = &quot;#72b1b1&quot; linewidth = 0.5 else: color = &quot;#72b1b1&quot; linewidth = 0.5 roadColors.append(color) roadWidths.append(linewidth) fig, ax = ox.plot_graph(Gwater, node_size=0,figsize=(27, 40), dpi = 300, save = False, edge_color=roadColors, edge_linewidth=roadWidths, edge_alpha=1) fig.tight_layout(pad=0) fig.savefig(&quot;water.png&quot;, dpi=300, format=&quot;png&quot;, bbox_inches=&#39;tight&#39;, facecolor=fig.get_facecolor(), transparent=True) "],["hypothesis-testing.html", "Chapter 3 Hypothesis testing 3.1 Importing a new module 3.2 Importing python packages 3.3 Correlation 3.4 Stationary tests 3.5 t-test of the sample mean 3.6 Testing for normality", " Chapter 3 Hypothesis testing 3.1 Importing a new module ## *Should not be needed* # Use conda install *package_name* to install a new module (in terminal) # Use reticulate::py_install(&quot;package_name&quot;) to load in that specific package to the R Studio environment # Then use import &quot;package_name&quot; to import the package into the relevant chunk 3.2 Importing python packages import matplotlib.pyplot as plt import matplotlib.dates as mdates import pandas as pd import numpy as np import statistics import statsmodels.api as sm from scipy.stats import norm from matplotlib.ticker import EngFormatter, StrMethodFormatter 3.3 Correlation Pearson’s Correlation Coefficient Tests whether two samples have a linear relationship. Assumptions Observations in each sample are independent and identically distributed (iid). Observations in each sample are normally distributed. Observations in each sample have the same variance. Interpretation H0: the two samples are independent. H1: there is a dependency between the samples. # Example of the Pearson&#39;s Correlation test from scipy.stats import pearsonr data1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869] data2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579] # Run the test stat, p = pearsonr(data1, data2) print(&#39;stat=%.3f, p=%.3f&#39; % (stat, p)) ## stat=0.688, p=0.028 if p &gt; 0.05: print(&#39;Datasets are not correlated&#39;) else: print(&#39;Datasets are correlated&#39;) ## Datasets are correlated 3.4 Stationary tests Augmented Dickey-Fuller Unit Root Test: This tests whether a time series has a unit root, e.g. has a trend or more generally is autoregressive. Assumptions Observations in are temporally ordered. Interpretation H0: a unit root is present (series is non-stationary). H1: a unit root is not present (series is stationary). # Example of the Augmented Dickey-Fuller unit root test from statsmodels.tsa.stattools import adfuller data = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # Run the test stat, p, lags, obs, crit, t = adfuller(data) print(&#39;stat=%.3f, p=%.3f&#39; % (stat, p)) ## stat=2.430, p=0.999 if p &gt; 0.05: print(&#39;Series is not stationary&#39;) else: print(&#39;Series is stationary&#39;) ## Series is not stationary 3.5 t-test of the sample mean Tests whether the means of two independent samples are significantly different. Assumptions Observations in each sample are independent and identically distributed (iid). Observations in each sample are normally distributed. Observations in each sample have the same variance. Interpretation H0: the means of the samples are equal. H1: the means of the samples are unequal. # Example of the Student&#39;s t-test from scipy.stats import ttest_ind data1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869] data2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169] # Run the test stat, p = ttest_ind(data1, data2) print(&#39;stat=%.3f, p=%.3f&#39; % (stat, p)) ## stat=-0.326, p=0.748 if p &gt; 0.05: print(&#39;Probably the same distribution&#39;) else: print(&#39;Probably different distributions&#39;) ## Probably the same distribution We can verify this result by using a normal distribution. For this, we use the function: np.random.normal(mu, sigma, 1000) # Create a normnal distribution with mean of 0 and a variance of 1 mu_0, sigma_0 = 0, 1 normal_dist_0 = np.random.normal(mu_0, sigma_0, 1000) # Chart count, bins, ignored = plt.hist(normal_dist_0, 30, density=True) plt.plot(bins, 1/(sigma_0 * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu_0)**2 / (2 * sigma_0**2) ), linewidth=2, color=&#39;orange&#39;) plt.show() Now we’ll re-run the code, but change the sample mean to 1 rather than 0. # Create a normnal distribution with mean of 1 and a variance of 1 mu_1, sigma_1 = 1, 1 normal_dist_1 = np.random.normal(mu_1, sigma_1, 1000) # Chart count, bins, ignored = plt.hist(normal_dist_1, 30, density=True) plt.plot(bins, 1/(sigma_1+1 * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu_1)**2 / (2 * sigma_1**2) ), linewidth=2, color=&#39;orange&#39;) plt.show() 3.6 Testing for normality The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution. Interpretation H0: sample is from a normal distribution H1: sample is not from a normal distribution from scipy import stats stats.shapiro(normal_dist_0) ## ShapiroResult(statistic=0.9984456300735474, pvalue=0.5196242928504944) stats.shapiro(normal_dist_1) ## ShapiroResult(statistic=0.9987215995788574, pvalue=0.7030749917030334) We can see here that the p-values are huge (well above 0.05) - and we fail to reject the null hypothesis. "],["regression-analysis.html", "Chapter 4 Regression analysis 4.1 Importing python packages 4.2 Create a model and fit it 4.3 Polynomial regression", " Chapter 4 Regression analysis 4.1 Importing python packages import matplotlib.pyplot as plt import matplotlib.dates as mdates import pandas as pd import numpy as np import statistics from scipy.stats import norm from matplotlib.ticker import EngFormatter, StrMethodFormatter The fundamental data type of NumPy is the array type called numpy.ndarray. The rest of this article uses the term array to refer to instances of the type numpy.ndarray. from sklearn.datasets import fetch_california_housing california_housing = fetch_california_housing(as_frame=True) print(california_housing.DESCR) california_housing.data.head() #Looks good - let&#39;s convert it into a pandas dataframe california_housing_df = pd.DataFrame(california_housing.data) print(california_housing_df) california_housing.frame.hist(figsize=(12, 10), bins=30, edgecolor=&quot;black&quot;) plt.subplots_adjust(hspace=0.7, wspace=0.4) plt.show() 4.2 Create a model and fit it The next step is to create the regression model as an instance of LinearRegression and fit it with .fit(). import sklearn from sklearn.linear_model import LinearRegression from sklearn import linear_model # Choose our variables of interest x = california_housing_df[[&#39;HouseAge&#39;]] y = california_housing_df[[&#39;MedInc&#39;]] # Make a model model = LinearRegression().fit(x, y) # Analyse the model fit r_sq = model.score(x, y) print(&#39;coefficient of determination:&#39;, r_sq) print(&#39;intercept:&#39;, model.intercept_) print(&#39;slope:&#39;, model.coef_) 4.3 Polynomial regression We can fit different order polynomials by defining the relevant polynomial functions. # Load in relevant packages from numpy import arange from pandas import read_csv from scipy.optimize import curve_fit from matplotlib import pyplot # Define the true objective function for a linear estimation def objective(x, a, b): return a * x + b # load the dataset url = &#39;https://raw.githubusercontent.com/jbrownlee/Datasets/master/longley.csv&#39; dataframe = read_csv(url, header=None) data = dataframe.values # choose the input and output variables x, y = data[:, 4], data[:, -1] # curve fit popt, _ = curve_fit(objective, x, y) # summarize the parameter values a, b = popt print(&#39;y = %.5f * x + %.5f&#39; % (a, b)) # plot input vs output plt.scatter(x, y, c =&quot;blue&quot;) # define a sequence of inputs between the smallest and largest known inputs x_line = arange(min(x), max(x), 1) # calculate the output for the range y_line = objective(x_line, a, b) # create a line plot for the mapping function plt.plot(x_line, y_line, label=&#39;Polynomial&#39;, color=&#39;purple&#39;, alpha=1, linewidth=1.2, linestyle=&#39;dashed&#39;) plt.title(&#39;Using a linear model to approximate data&#39;, fontsize=12) plt.xlabel(&#39;&#39;, fontsize=10) plt.ylabel(&#39;&#39;, fontsize=10) plt.gca().spines[&#39;top&#39;].set_visible(False) plt.gca().spines[&#39;bottom&#39;].set_visible(True) plt.gca().spines[&#39;right&#39;].set_visible(False) plt.gca().spines[&#39;left&#39;].set_visible(False) plt.tick_params( axis=&#39;x&#39;, # changes apply to the x-axis which=&#39;both&#39;, # both major and minor ticks are affected bottom=False, # ticks along the bottom edge are off top=False, # ticks along the top edge are off labelbottom=True) # labels along the bottom edge are off plt.tick_params( axis=&#39;y&#39;, # changes apply to the y-axis which=&#39;both&#39;, # both major and minor ticks are affected left=False, # ticks along the bottom edge are off right=False, # ticks along the top edge are off labelleft=True) # labels along the bottom edge are off plt.grid(False) plt.gca().yaxis.grid(True) plt.legend(fancybox=False, framealpha=1, shadow=False, borderpad=1) plt.savefig(&#39;linear_model_chart.png&#39;,dpi=300,bbox_inches=&#39;tight&#39;) plt.show() Now let’s try a polynomial model # Fit a second degree polynomial to the economic data from numpy import arange from pandas import read_csv from scipy.optimize import curve_fit from matplotlib import pyplot # Define the true objective function def objective(x, a, b, c): return a * x + b * x**2 + c # Load the dataset url = &#39;https://raw.githubusercontent.com/jbrownlee/Datasets/master/longley.csv&#39; dataframe = read_csv(url, header=None) data = dataframe.values # choose the input and output variables x, y = data[:, 4], data[:, -1] # curve fit popt, _ = curve_fit(objective, x, y) # summarize the parameter values a, b, c = popt print(&#39;y = %.5f * x + %.5f * x^2 + %.5f&#39; % (a, b, c)) # plot input vs output plt.scatter(x, y, c =&quot;blue&quot;) # define a sequence of inputs between the smallest and largest known inputs x_line = arange(min(x), max(x), 1) # calculate the output for the range y_line = objective(x_line, a, b, c) # create a line plot for the mapping function # create a line plot for the mapping function plt.plot(x_line, y_line, label=&#39;Polynomial&#39;, color=&#39;purple&#39;, alpha=1, linewidth=1.2, linestyle=&#39;dashed&#39;) plt.title(&#39;Using a polynomial model to approximate data&#39;, fontsize=12) plt.xlabel(&#39;&#39;, fontsize=10) plt.ylabel(&#39;&#39;, fontsize=10) plt.gca().spines[&#39;top&#39;].set_visible(False) plt.gca().spines[&#39;bottom&#39;].set_visible(True) plt.gca().spines[&#39;right&#39;].set_visible(False) plt.gca().spines[&#39;left&#39;].set_visible(False) plt.tick_params( axis=&#39;x&#39;, # changes apply to the x-axis which=&#39;both&#39;, # both major and minor ticks are affected bottom=False, # ticks along the bottom edge are off top=False, # ticks along the top edge are off labelbottom=True) # labels along the bottom edge are off plt.tick_params( axis=&#39;y&#39;, # changes apply to the y-axis which=&#39;both&#39;, # both major and minor ticks are affected left=False, # ticks along the bottom edge are off right=False, # ticks along the top edge are off labelleft=True) # labels along the bottom edge are off plt.grid(False) plt.gca().yaxis.grid(True) plt.legend(fancybox=False, framealpha=1, shadow=False, borderpad=1) plt.savefig(&#39;linear_model_chart.png&#39;,dpi=300,bbox_inches=&#39;tight&#39;) plt.show() "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
